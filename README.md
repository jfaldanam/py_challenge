# 2025 - Python challenge

This Python challenge was designed for the students of the first edition of the Master's in Big Data, Artificial Intelligence, and Data Engineering at the University of MÃ¡laga.

This challenge is designed in a modular format so that if you get stuck on one of the steps, you can continue working on the rest, while covering **most** of the topics studied during the course.

# Challenge description

The goal of this challenge is to create an end-to-end application to classify animals into four classes (Kangaroo, Elephant, Chicken, and Dog) based on a set of characteristics.

The challenge is split into 5 steps, each one building on top of the previous one. You can choose to complete all of them or just some of them.

Each step will have a main goal and a set of self-evaluation points that you can use to check if you have fulfilled all the requirements to implement a quality solution. Some of them are considered extra and are not required for the solution to work.

## 0 - General requirements

To practice in a more real-world scenario, you should use Git to version your code and GitHub to submit your solution. Follow best practices of Git, like writing meaningful commit messages, using branches, and pull requests (even if it's just for yourself).

Additionally, try to follow best practices of Python, like using type hints, docstrings, and the PEP8 style guide (bonus points for configuring a linter like `ruff` or `black` in your project).

Split your code into modules and functions to make it more readable and reusable.

## 1 - Prepare the development environment

I have prepared a service that will provide you with the data required for the rest of the steps.

Check [`data-service/`](data-service/) for instructions on the deployment. You should not need to read or modify the Python code, treat this as an external service that you deploy locally.

All you need is in the README.md or the web application itself.

**Main goal**: You have a local instance of the data service you can connect in order to obtain data.

<details>
<summary>Self-evaluation of your progress</summary>

- [ ] You have built the container with the instructions provided.
- [ ] You have deployed the container with the instructions provided.
- [ ] You can access the app and its documentation on your local machine.
- [ ] You can request data and receive it through one of the provided test commands.

</details>

## 2 - Data preprocessing and machine learning

With the data generated by the data service, we want to classify at least 1,000 datapoints into the 4 classes provided (Kangaroo, Elephant, Chicken, and Dog).

Visualize the data to better understand it, clean it from outliers, and train a machine learning model to classify the data.

> [!NOTE]  
> Data received from the data service is not labeled. This is left as an exercise for you to solve.  
> There is more than one way to solve this problem, and you can choose the one that you feel most comfortable with.

**Main goal**: Have a Python script to remove outliers and classify the data, and a Jupyter notebook with the visualizations used.

<details>
<summary>Self-evaluation of your progress</summary>

- [ ] You have read all the information you could gather on the data from the data service.
- [ ] You have prepared a dataset with at least 1,000 datapoints locally from the data service.
- [ ] You have visualized the data to better understand its structure.
- [ ] You have cleaned the data of outliers.
- [ ] You have trained a machine learning model on the data to solve the requested task.
- [ ] You have stored the model in a way that can be loaded later.
- [ ] You have validated the results from the model according to the knowledge you have on the data.
- [ ] (EXTRA) If your approach allows it, provide a confidence interval for the predictions.
- [ ] (EXTRA) When training the model, you store it in object storage (like [min.io](https://min.io)) instead of the local filesystem.

</details>

## 3 - Backend development

Create an API that uses the model trained in the previous exercise to classify data provided by a user.

**Main goal**: You have a REST API that can be queried to classify new data.

<details>
<summary>Self-evaluation of your progress</summary>

- [ ] You have a REST API, and you can access the documentation.
- [ ] You have an endpoint to predict a data point.
- [ ] (EXTRA) You have an endpoint to re-train the model with new data.
- [ ] (EXTRA) Your API is properly typed with Pydantic models.
- [ ] (EXTRA) Your API is built as a Python package.
- [ ] (EXTRA) Your API has a CLI command that allows configuring basic parameters.
- [ ] (EXTRA) Your API loads the model from object storage instead of the local filesystem.
- [ ] (EXTRA) Implement at least 5 unit tests for some of your functions.
- [ ] (EXTRA) When running the tests, you measure the coverage of your tests.
- [ ] (EXTRA) Your package has a README that explains how to deploy the app and basic information about how to use it (running, tests, etc.).

</details>

## 4 - Front-end PoC/Visualization

Build a dashboard (for example with [streamlit](https://streamlit.io/)) that can be used as a client for the API built in the previous step.

**Main goal**: A web interface accessible through the browser is available for users to provide a new sample and get a classification for it.

<details>
<summary>Self-evaluation of your progress</summary>

- [ ] You have a web app that can be accessed through a browser.
- [ ] The user can input their data through the web app.
- [ ] When a user sends their data, the backend is contacted to classify it.
- [ ] (EXTRA) When the user sends their data, the data and the classification are stored in a SQL database so it can be used for re-training the model in the future.
- [ ] (EXTRA) If data is being stored in a database, the web app can show the user a table with the data it has sent and the classification it received.
- [ ] (EXTRA) Your web app is built as a Python package.
- [ ] (EXTRA) Your package has a README that explains how to deploy the app and basic information about it.

</details>

## 5 - Containerization

To facilitate the deployment of all the components created, create a container for each of them.

Additionally, prepare a Docker Compose file that will help end users deploy **all** the components together with a single command.

**Main goal**: A single command can be used to run the whole application, including the backend, frontend, and the data service provided.

<details>
<summary>Self-evaluation of your progress</summary>

- [ ] The backend can be deployed with Docker.
- [ ] The web app can be deployed with Docker.
- [ ] (EXTRA) There is a Docker Compose file in the root of the repository that deploys the data service, the backend, and the web app directly.
- [ ] (EXTRA) If applicable, the database used by the backend is also deployed with Docker and configured in the Docker Compose file.
- [ ] (EXTRA) Each part's README.md includes documentation on deploying with Docker.

</details>

# How to submit your solution for evaluation?

First, create a repository in your GitHub account with the solution to the challenge. Please make sure to include a README.md file with instructions on how to run your solution.

Once you are done with the challenge, please open a pull request in this repository, modifying this README.md by adding a link to your repository in the table below.

Then, I will provide feedback on your solution, and we can discuss it further inside the PR. Additionally, the rest of the students can see your solution and the feedback provided, so we can learn from everyone.

# Solutions to this challenge

| Link to the repository |
|------------------------|
| [jfaldanam/py_challenge_solution](https://github.com/jfaldanam/py_challenge_solution) |
| [cberdejo/python-machine-learning-challenge](https://github.com/cberdejo/python-machine-learning-challenge)|
